{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Anthropic Interviewer – Human-Only Conversation Dataset\n",
        "\n",
        "**Dataset source:** Hugging Face `Anthropic/AnthropicInterviewer` (workforce, creatives, scientists splits).\n",
        "\n",
        "**Goal:** Merge all splits and keep only human speech for analysis — one row per transcript with human turns in chronological order."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e67ef229",
      "metadata": {},
      "source": [
        "## BDD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3c00b43",
      "metadata": {},
      "source": [
        "### Imports et préparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "00abafcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install datasets pandas tqdm pyarrow  # uncomment if needed\n",
        "\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75121e9e",
      "metadata": {},
      "source": [
        "### BDD et préparation – Chargement et fusion des splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2847ee03",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (1250, 3)\n",
            "\n",
            "Split counts:\n",
            "split\n",
            "workforce     1000\n",
            "creatives      125\n",
            "scientists     125\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "ds = load_dataset(\"Anthropic/AnthropicInterviewer\")\n",
        "\n",
        "workforce = ds[\"workforce\"].to_pandas()\n",
        "creatives = ds[\"creatives\"].to_pandas()\n",
        "scientists = ds[\"scientists\"].to_pandas()\n",
        "\n",
        "workforce[\"split\"] = \"workforce\"\n",
        "creatives[\"split\"] = \"creatives\"\n",
        "scientists[\"split\"] = \"scientists\"\n",
        "\n",
        "df_raw = pd.concat([\n",
        "    workforce[[\"split\", \"transcript_id\", \"text\"]],\n",
        "    creatives[[\"split\", \"transcript_id\", \"text\"]],\n",
        "    scientists[[\"split\", \"transcript_id\", \"text\"]],\n",
        "], ignore_index=True)\n",
        "\n",
        "print(\"Shape:\", df_raw.shape)\n",
        "print(\"\\nSplit counts:\")\n",
        "print(df_raw[\"split\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4084bd2",
      "metadata": {},
      "source": [
        "### Utilitaires de parsing (speaker, nettoyage, transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "19759323",
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_speaker(line):\n",
        "    \"\"\"Return 'AI', 'HUMAN', or 'unknown' based on line prefix.\"\"\"\n",
        "    line_lower = line.strip().lower()\n",
        "    if any(line_lower.startswith(p) for p in (\"assistant:\", \"claude:\", \"interviewer:\")):\n",
        "        return \"AI\"\n",
        "    if any(line_lower.startswith(p) for p in (\"user:\", \"participant:\", \"interviewee:\")):\n",
        "        return \"HUMAN\"\n",
        "    return \"unknown\"\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Remove speaker prefix and normalize whitespace.\"\"\"\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"^(Assistant|Claude|Interviewer|User|Participant|Interviewee):\\s*\", \"\", text, flags=re.IGNORECASE)\n",
        "    return \" \".join(text.split()).strip()\n",
        "\n",
        "\n",
        "def parse_transcript(text):\n",
        "    \"\"\"\n",
        "    Parse transcript into list of (speaker, text) turns.\n",
        "    Splits on common speaker prefixes and returns chronological turns.\n",
        "    \"\"\"\n",
        "    if not text or not isinstance(text, str):\n",
        "        return []\n",
        "    lines = [ln.strip() for ln in text.split(\"\\n\") if ln.strip()]\n",
        "    turns = []\n",
        "    current_speaker = None\n",
        "    current_text = []\n",
        "    for line in lines:\n",
        "        speaker = detect_speaker(line)\n",
        "        if speaker != \"unknown\":\n",
        "            if current_speaker is not None and current_text:\n",
        "                turns.append((current_speaker, clean_text(\" \".join(current_text))))\n",
        "            current_speaker = speaker\n",
        "            current_text = [line]\n",
        "        else:\n",
        "            if current_text:\n",
        "                current_text.append(line)\n",
        "    if current_speaker is not None and current_text:\n",
        "        turns.append((current_speaker, clean_text(\" \".join(current_text))))\n",
        "    return turns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d715de38",
      "metadata": {},
      "source": [
        "### Construction du jeu human-only (1 ligne = 1 transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "366a86b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parsing transcripts: 100%|██████████| 1250/1250 [00:01<00:00, 1088.50it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>n_human_turns</th>\n",
              "      <th>truncated</th>\n",
              "      <th>human_turn_01</th>\n",
              "      <th>human_turn_02</th>\n",
              "      <th>human_turn_03</th>\n",
              "      <th>human_turn_04</th>\n",
              "      <th>human_turn_05</th>\n",
              "      <th>human_turn_06</th>\n",
              "      <th>...</th>\n",
              "      <th>human_turn_31</th>\n",
              "      <th>human_turn_32</th>\n",
              "      <th>human_turn_33</th>\n",
              "      <th>human_turn_34</th>\n",
              "      <th>human_turn_35</th>\n",
              "      <th>human_turn_36</th>\n",
              "      <th>human_turn_37</th>\n",
              "      <th>human_turn_38</th>\n",
              "      <th>human_turn_39</th>\n",
              "      <th>human_turn_40</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>workforce</td>\n",
              "      <td>work_0000</td>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>No, I don't have any questions. Let's do it! A...</td>\n",
              "      <td>I pretty rarely use AI in my typical workday. ...</td>\n",
              "      <td>I will open the AI model and provide it with a...</td>\n",
              "      <td>I always modify them. They're never \"perfect\"....</td>\n",
              "      <td>I do not believe there are any tasks that AI c...</td>\n",
              "      <td>I turn to AI when I'm stuck. For example, if t...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>workforce</td>\n",
              "      <td>work_0001</td>\n",
              "      <td>12</td>\n",
              "      <td>False</td>\n",
              "      <td>That sounds good. AI: Great! Let's dive in the...</td>\n",
              "      <td>I use AI sparingly at my job. I only use it to...</td>\n",
              "      <td>I use Grammarly primarily. I'd been asked to u...</td>\n",
              "      <td>Sure. I almost always use its spelling suggest...</td>\n",
              "      <td>For the most part, I'd prefer to handle anythi...</td>\n",
              "      <td>Sure. It's important that my clients can under...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>workforce</td>\n",
              "      <td>work_0002</td>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>No questions, we can begin AI: Great! Let's di...</td>\n",
              "      <td>I've used it primarily in the creation of spre...</td>\n",
              "      <td>So using my specific use case example, I would...</td>\n",
              "      <td>From my past experience, it usually takes a co...</td>\n",
              "      <td>well the deciding factor for me is, if Im spen...</td>\n",
              "      <td>Unfortunately, I haven't found any tasks or si...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>workforce</td>\n",
              "      <td>work_0003</td>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>Soinds good. Let's proceed. AI: Great! Let's d...</td>\n",
              "      <td>I'm in real estate so I use Ai for a variety o...</td>\n",
              "      <td>For property descriptions I will typically ent...</td>\n",
              "      <td>I definitely include the basics of room count,...</td>\n",
              "      <td>Definitely, I've chosen not to utilize any Ai ...</td>\n",
              "      <td>I think I would need to feel confident that th...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>workforce</td>\n",
              "      <td>work_0004</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>Sounds good to me, let's begin. AI: Great! Let...</td>\n",
              "      <td>I'm a data analyst at SUEZ and I use AI for a ...</td>\n",
              "      <td>Yes , I often tell it to write the entire code...</td>\n",
              "      <td>I'd prefer if AI could handle it independently...</td>\n",
              "      <td>Yes , for super sensitive information, like bu...</td>\n",
              "      <td>I am the only person who really uses AI. I wor...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>scientists</td>\n",
              "      <td>science_0120</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>That sounds good, I have no questions at this ...</td>\n",
              "      <td>A recent project I've worked on is building a ...</td>\n",
              "      <td>I use Python extensively in my work, because i...</td>\n",
              "      <td>I found that it was much faster to decompose s...</td>\n",
              "      <td>Sometimes decisions are made using information...</td>\n",
              "      <td>I'll often test the functions on small synthet...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>scientists</td>\n",
              "      <td>science_0121</td>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>Yes that sounds good. I have no questions. AI:...</td>\n",
              "      <td>The research component of my work largely invo...</td>\n",
              "      <td>The first time we used AI was to ask about how...</td>\n",
              "      <td>We needed a data structure that enabled us to ...</td>\n",
              "      <td>We asked the AI to pull out the data points we...</td>\n",
              "      <td>So, calculating weighted arithmetic means of g...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>scientists</td>\n",
              "      <td>science_0122</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>No AI: Great! Let's dive in then. To start, co...</td>\n",
              "      <td>I was working on getting ideas for a dissertat...</td>\n",
              "      <td>I am still mulling over the type of dissertati...</td>\n",
              "      <td>Having AI search for keywords reduced the time...</td>\n",
              "      <td>If a reference was provided by the authors, I ...</td>\n",
              "      <td>I haven't begun developing my methodology as y...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1248</th>\n",
              "      <td>scientists</td>\n",
              "      <td>science_0123</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>Sounds good to me! AI: Wonderful! Let's dive r...</td>\n",
              "      <td>I've been working with my student on investiga...</td>\n",
              "      <td>I had the idea when I was in grad school, but ...</td>\n",
              "      <td>Yes, not initially, but when it came time to a...</td>\n",
              "      <td>I've wanted to learn R for a long time, but I'...</td>\n",
              "      <td>I had a gut feeling based on visuals what the ...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>scientists</td>\n",
              "      <td>science_0124</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>Sounds good. AI: Great! Let's dive in then. I'...</td>\n",
              "      <td>I've been working on a project to develop bett...</td>\n",
              "      <td>The idea grew out of other work that my lab wa...</td>\n",
              "      <td>Our primary use of AI has been in literature s...</td>\n",
              "      <td>Because this project involves a wide range of ...</td>\n",
              "      <td>We're still not 100% convinced that AI is reli...</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1250 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           split transcript_id  n_human_turns  truncated  \\\n",
              "0      workforce     work_0000             13      False   \n",
              "1      workforce     work_0001             12      False   \n",
              "2      workforce     work_0002             11      False   \n",
              "3      workforce     work_0003             13      False   \n",
              "4      workforce     work_0004             10      False   \n",
              "...          ...           ...            ...        ...   \n",
              "1245  scientists  science_0120              8      False   \n",
              "1246  scientists  science_0121             11      False   \n",
              "1247  scientists  science_0122              9      False   \n",
              "1248  scientists  science_0123             10      False   \n",
              "1249  scientists  science_0124             10      False   \n",
              "\n",
              "                                          human_turn_01  \\\n",
              "0     No, I don't have any questions. Let's do it! A...   \n",
              "1     That sounds good. AI: Great! Let's dive in the...   \n",
              "2     No questions, we can begin AI: Great! Let's di...   \n",
              "3     Soinds good. Let's proceed. AI: Great! Let's d...   \n",
              "4     Sounds good to me, let's begin. AI: Great! Let...   \n",
              "...                                                 ...   \n",
              "1245  That sounds good, I have no questions at this ...   \n",
              "1246  Yes that sounds good. I have no questions. AI:...   \n",
              "1247  No AI: Great! Let's dive in then. To start, co...   \n",
              "1248  Sounds good to me! AI: Wonderful! Let's dive r...   \n",
              "1249  Sounds good. AI: Great! Let's dive in then. I'...   \n",
              "\n",
              "                                          human_turn_02  \\\n",
              "0     I pretty rarely use AI in my typical workday. ...   \n",
              "1     I use AI sparingly at my job. I only use it to...   \n",
              "2     I've used it primarily in the creation of spre...   \n",
              "3     I'm in real estate so I use Ai for a variety o...   \n",
              "4     I'm a data analyst at SUEZ and I use AI for a ...   \n",
              "...                                                 ...   \n",
              "1245  A recent project I've worked on is building a ...   \n",
              "1246  The research component of my work largely invo...   \n",
              "1247  I was working on getting ideas for a dissertat...   \n",
              "1248  I've been working with my student on investiga...   \n",
              "1249  I've been working on a project to develop bett...   \n",
              "\n",
              "                                          human_turn_03  \\\n",
              "0     I will open the AI model and provide it with a...   \n",
              "1     I use Grammarly primarily. I'd been asked to u...   \n",
              "2     So using my specific use case example, I would...   \n",
              "3     For property descriptions I will typically ent...   \n",
              "4     Yes , I often tell it to write the entire code...   \n",
              "...                                                 ...   \n",
              "1245  I use Python extensively in my work, because i...   \n",
              "1246  The first time we used AI was to ask about how...   \n",
              "1247  I am still mulling over the type of dissertati...   \n",
              "1248  I had the idea when I was in grad school, but ...   \n",
              "1249  The idea grew out of other work that my lab wa...   \n",
              "\n",
              "                                          human_turn_04  \\\n",
              "0     I always modify them. They're never \"perfect\"....   \n",
              "1     Sure. I almost always use its spelling suggest...   \n",
              "2     From my past experience, it usually takes a co...   \n",
              "3     I definitely include the basics of room count,...   \n",
              "4     I'd prefer if AI could handle it independently...   \n",
              "...                                                 ...   \n",
              "1245  I found that it was much faster to decompose s...   \n",
              "1246  We needed a data structure that enabled us to ...   \n",
              "1247  Having AI search for keywords reduced the time...   \n",
              "1248  Yes, not initially, but when it came time to a...   \n",
              "1249  Our primary use of AI has been in literature s...   \n",
              "\n",
              "                                          human_turn_05  \\\n",
              "0     I do not believe there are any tasks that AI c...   \n",
              "1     For the most part, I'd prefer to handle anythi...   \n",
              "2     well the deciding factor for me is, if Im spen...   \n",
              "3     Definitely, I've chosen not to utilize any Ai ...   \n",
              "4     Yes , for super sensitive information, like bu...   \n",
              "...                                                 ...   \n",
              "1245  Sometimes decisions are made using information...   \n",
              "1246  We asked the AI to pull out the data points we...   \n",
              "1247  If a reference was provided by the authors, I ...   \n",
              "1248  I've wanted to learn R for a long time, but I'...   \n",
              "1249  Because this project involves a wide range of ...   \n",
              "\n",
              "                                          human_turn_06  ... human_turn_31  \\\n",
              "0     I turn to AI when I'm stuck. For example, if t...  ...                 \n",
              "1     Sure. It's important that my clients can under...  ...                 \n",
              "2     Unfortunately, I haven't found any tasks or si...  ...                 \n",
              "3     I think I would need to feel confident that th...  ...                 \n",
              "4     I am the only person who really uses AI. I wor...  ...                 \n",
              "...                                                 ...  ...           ...   \n",
              "1245  I'll often test the functions on small synthet...  ...                 \n",
              "1246  So, calculating weighted arithmetic means of g...  ...                 \n",
              "1247  I haven't begun developing my methodology as y...  ...                 \n",
              "1248  I had a gut feeling based on visuals what the ...  ...                 \n",
              "1249  We're still not 100% convinced that AI is reli...  ...                 \n",
              "\n",
              "     human_turn_32 human_turn_33 human_turn_34 human_turn_35 human_turn_36  \\\n",
              "0                                                                            \n",
              "1                                                                            \n",
              "2                                                                            \n",
              "3                                                                            \n",
              "4                                                                            \n",
              "...            ...           ...           ...           ...           ...   \n",
              "1245                                                                         \n",
              "1246                                                                         \n",
              "1247                                                                         \n",
              "1248                                                                         \n",
              "1249                                                                         \n",
              "\n",
              "     human_turn_37 human_turn_38 human_turn_39 human_turn_40  \n",
              "0                                                             \n",
              "1                                                             \n",
              "2                                                             \n",
              "3                                                             \n",
              "4                                                             \n",
              "...            ...           ...           ...           ...  \n",
              "1245                                                          \n",
              "1246                                                          \n",
              "1247                                                          \n",
              "1248                                                          \n",
              "1249                                                          \n",
              "\n",
              "[1250 rows x 44 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_HUMAN_TURNS = 40\n",
        "\n",
        "rows = []\n",
        "for _, row in tqdm(df_raw.iterrows(), total=len(df_raw), desc=\"Parsing transcripts\"):\n",
        "    split = row[\"split\"]\n",
        "    transcript_id = row[\"transcript_id\"]\n",
        "    text = row[\"text\"]\n",
        "    turns = parse_transcript(text)\n",
        "    human_turns = [t[1] for t in turns if t[0] == \"HUMAN\" and t[1]]\n",
        "    truncated = len(human_turns) > MAX_HUMAN_TURNS\n",
        "    if truncated:\n",
        "        human_turns = human_turns[:MAX_HUMAN_TURNS]\n",
        "    n_human_turns = len(human_turns)\n",
        "    out = {\n",
        "        \"split\": split,\n",
        "        \"transcript_id\": transcript_id,\n",
        "        \"n_human_turns\": n_human_turns,\n",
        "        \"truncated\": truncated,\n",
        "    }\n",
        "    for i in range(1, MAX_HUMAN_TURNS + 1):\n",
        "        out[f\"human_turn_{i:02d}\"] = human_turns[i - 1] if i <= n_human_turns else \"\"\n",
        "    rows.append(out)\n",
        "\n",
        "df_final = pd.DataFrame(rows)\n",
        "df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8748d7",
      "metadata": {},
      "source": [
        "### Contrôles de cohérence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5992ad8a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total transcripts: 1250\n",
            "Mean n_human_turns: 11.6\n",
            "\n",
            "Stats per split:\n",
            "            count  mean_turns\n",
            "split                        \n",
            "creatives     125       10.07\n",
            "scientists    125        9.28\n",
            "workforce    1000       12.08\n",
            "\n",
            "% truncated: 0.0 %\n",
            "\n",
            "Assertion passed: no AI text in df_final human turn columns.\n"
          ]
        }
      ],
      "source": [
        "print(\"Total transcripts:\", len(df_final))\n",
        "print(\"Mean n_human_turns:\", df_final[\"n_human_turns\"].mean().round(2))\n",
        "print(\"\\nStats per split:\")\n",
        "print(df_final.groupby(\"split\").agg(\n",
        "    count=(\"transcript_id\", \"count\"),\n",
        "    mean_turns=(\"n_human_turns\", \"mean\"),\n",
        ").round(2))\n",
        "print(\"\\n% truncated:\", (df_final[\"truncated\"].sum() / len(df_final) * 100).round(1), \"%\")\n",
        "\n",
        "# Assert no AI text in human turn columns\n",
        "ai_prefixes = (\"assistant:\", \"claude:\", \"interviewer:\")\n",
        "turn_cols = [c for c in df_final.columns if c.startswith(\"human_turn_\")]\n",
        "for col in turn_cols:\n",
        "    for val in df_final[col].dropna():\n",
        "        if val and isinstance(val, str):\n",
        "            val_lower = val[:50].lower()\n",
        "            assert not any(val_lower.startswith(p) for p in ai_prefixes), f\"AI text in {col}\"\n",
        "print(\"\\nAssertion passed: no AI text in df_final human turn columns.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6ec0773",
      "metadata": {},
      "source": [
        "### Export (CSV et Parquet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9a321949",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: out\\df_final.csv out\\df_final.parquet\n"
          ]
        }
      ],
      "source": [
        "out_dir = Path(\"./out\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "df_final.to_csv(out_dir / \"df_final.csv\", index=False)\n",
        "df_final.to_parquet(out_dir / \"df_final.parquet\", index=False)\n",
        "\n",
        "print(\"Saved:\", out_dir / \"df_final.csv\", out_dir / \"df_final.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8093ec14",
      "metadata": {},
      "source": [
        "## Début d'analyses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09da52ce",
      "metadata": {},
      "source": [
        "### 1ère analyse : Discours vs réalité"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d103779d",
      "metadata": {},
      "source": [
        "Dans cette partie, je m’intéresse à ce que j’appelle le décalage entre le discours et la réalité du travail avec l’IA.\n",
        "\n",
        "Quand les personnes parlent de leur usage de l’IA dans un cadre officiel, comme une interview, elles ne décrivent pas seulement ce qu’elles font concrètement. Elles décrivent aussi ce qu’il est socialement acceptable de dire.\n",
        "\n",
        "On observe très souvent des formulations prudentes, par exemple : “Je m’en sers juste pour corriger l’orthographe” ou “je fais attention à ne pas trop déléguer”.\n",
        "\n",
        "Mais dans le même entretien, ces mêmes personnes expliquent ensuite qu’elles génèrent des campagnes complètes, des rapports, ou qu’elles s’appuient sur l’IA pour prendre des décisions importantes.\n",
        "\n",
        "L’objectif ici n’est pas de dire que les gens mentent, mais de montrer qu’il existe déjà une norme implicite autour du “bon usage” de l’IA.\n",
        "\n",
        "Autrement dit, l’impact de l’IA sur le travail commence d’abord dans la manière dont on en parle, avant même de se voir clairement dans les tâches elles-mêmes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25792bfd",
      "metadata": {},
      "source": [
        "#### LLM Annotation (Ollama / qwen2.5:7b-instruct)\n",
        "\n",
        "But : annoter automatiquement tous les tours **humains** présents dans `df_final` via un LLM local.\n",
        "Modèle : `qwen2.5:7b-instruct` via Ollama (`http://localhost:11434`).\n",
        "Outputs : `df_final_annot` (turn-level annoté), `df_metrics` (Axe 1) + graphes matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "768f4c32",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama OK. Models available (sample): ['qwen2.5:7b-instruct']\n",
            "Model found: qwen2.5:7b-instruct\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
        "MODEL_NAME = \"qwen2.5:7b-instruct\"\n",
        "\n",
        "def _ollama_get_tags():\n",
        "    r = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\", timeout=10)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "try:\n",
        "    tags = _ollama_get_tags()\n",
        "    models = tags.get(\"models\", [])\n",
        "    model_names = [m.get(\"name\") for m in models if isinstance(m, dict)]\n",
        "    print(\"Ollama OK. Models available (sample):\", model_names[:10])\n",
        "    if MODEL_NAME not in model_names:\n",
        "        print(f\"\\nModel '{MODEL_NAME}' not found in /api/tags.\")\n",
        "        print(f\"Run: ollama pull {MODEL_NAME}\")\n",
        "    else:\n",
        "        print(f\"Model found: {MODEL_NAME}\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to reach Ollama at\", OLLAMA_BASE_URL)\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "580a845d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "_INVISIBLES_RE = re.compile(r\"[\\u200B-\\u200F\\u202A-\\u202E\\u2060-\\u206F\\ufeff]\")\n",
        "_WS_RE = re.compile(r\"[ \\t\\r\\f\\v]+\")\n",
        "\n",
        "\n",
        "def clean_text_basic(s):\n",
        "    \"\"\"Basic cleanup: remove invisibles, normalize whitespace/newlines, strip.\"\"\"\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    if not isinstance(s, str):\n",
        "        s = str(s)\n",
        "    s = _INVISIBLES_RE.sub(\"\", s)\n",
        "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    # Normalize horizontal whitespace\n",
        "    s = _WS_RE.sub(\" \", s)\n",
        "    # Collapse too many blank lines\n",
        "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
        "    return s.strip()\n",
        "\n",
        "\n",
        "def strict_json_load(s):\n",
        "    \"\"\"Load strict JSON; if it fails, try extracting first JSON array block.\"\"\"\n",
        "    if s is None:\n",
        "        raise ValueError(\"Cannot parse JSON from None\")\n",
        "    if not isinstance(s, str):\n",
        "        s = str(s)\n",
        "\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Try extract first top-level JSON array\n",
        "    start = s.find(\"[\")\n",
        "    end = s.rfind(\"]\")\n",
        "    if start != -1 and end != -1 and end > start:\n",
        "        candidate = s[start : end + 1]\n",
        "        return json.loads(candidate)\n",
        "\n",
        "    raise ValueError(\"Invalid JSON (expected a JSON array)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a165eb35",
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are an annotation engine.\n",
        "\n",
        "Task: For each human turn, classify the *stance* about AI usage.\n",
        "\n",
        "Labels (choose exactly one):\n",
        "- MINIMIZATION: downplays AI use, frames it as minor, safe, superficial, or \"just\" for small tasks.\n",
        "- PRACTICAL_USE: describes concrete, substantive, or workflow-integrated AI use (generation, decision support, automation, production use).\n",
        "- NEUTRAL: neither downplays nor describes substantive use; unclear/mixed without clear stance.\n",
        "\n",
        "Rules:\n",
        "- Do NOT judge truthfulness, honesty, or intention.\n",
        "- Do NOT infer beyond the text.\n",
        "- Return STRICT JSON ONLY. No prose, no markdown.\n",
        "\n",
        "Output schema: a JSON array of objects, one per input record, with fields:\n",
        "- row_id (string): copied from input\n",
        "- label (string): one of MINIMIZATION | PRACTICAL_USE | NEUTRAL\n",
        "- confidence (number): between 0 and 1\n",
        "- evidence (string): a short quote/span from the input supporting the label\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _validate_annotation_item(item):\n",
        "    if not isinstance(item, dict):\n",
        "        raise ValueError(\"Each output item must be an object\")\n",
        "    for k in (\"row_id\", \"label\", \"confidence\", \"evidence\"):\n",
        "        if k not in item:\n",
        "            raise ValueError(f\"Missing field: {k}\")\n",
        "\n",
        "    row_id = item[\"row_id\"]\n",
        "    label = item[\"label\"]\n",
        "    conf = item[\"confidence\"]\n",
        "    ev = item[\"evidence\"]\n",
        "\n",
        "    if not isinstance(row_id, str) or not row_id:\n",
        "        raise ValueError(\"row_id must be a non-empty string\")\n",
        "    if label not in {\"MINIMIZATION\", \"PRACTICAL_USE\", \"NEUTRAL\"}:\n",
        "        raise ValueError(\"Invalid label\")\n",
        "    if not isinstance(conf, (int, float)) or not (0 <= float(conf) <= 1):\n",
        "        raise ValueError(\"confidence must be in [0,1]\")\n",
        "    if not isinstance(ev, str):\n",
        "        raise ValueError(\"evidence must be a string\")\n",
        "\n",
        "    return {\n",
        "        \"row_id\": row_id,\n",
        "        \"label\": label,\n",
        "        \"confidence\": float(conf),\n",
        "        \"evidence\": ev.strip(),\n",
        "    }\n",
        "\n",
        "\n",
        "def call_ollama(batch_records, max_retries=2, sleep_s=0.5):\n",
        "    \"\"\"Call Ollama generate API with strict JSON parsing + repair retries.\"\"\"\n",
        "    if not isinstance(batch_records, list) or not batch_records:\n",
        "        return []\n",
        "\n",
        "    input_json = json.dumps(batch_records, ensure_ascii=False)\n",
        "\n",
        "    base_prompt = (\n",
        "        \"INPUT JSON:\\n\"\n",
        "        + input_json\n",
        "        + \"\\n\\nOUTPUT JSON ONLY:\"  # force strict\n",
        "    )\n",
        "\n",
        "    def _post(prompt_text):\n",
        "        payload = {\n",
        "            \"model\": MODEL_NAME,\n",
        "            \"stream\": False,\n",
        "            \"system\": SYSTEM_PROMPT,\n",
        "            \"prompt\": prompt_text,\n",
        "            \"options\": {\"temperature\": 0},\n",
        "        }\n",
        "        r = requests.post(f\"{OLLAMA_BASE_URL}/api/generate\", json=payload, timeout=120)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        return data.get(\"response\", \"\")\n",
        "\n",
        "    prompt = base_prompt\n",
        "    last_raw = None\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        raw = _post(prompt)\n",
        "        last_raw = raw\n",
        "        try:\n",
        "            parsed = strict_json_load(raw)\n",
        "            if not isinstance(parsed, list):\n",
        "                raise ValueError(\"Top-level JSON must be an array\")\n",
        "\n",
        "            cleaned = [_validate_annotation_item(x) for x in parsed]\n",
        "\n",
        "            expected = {str(r.get(\"row_id\")) for r in batch_records}\n",
        "            cleaned = [x for x in cleaned if x[\"row_id\"] in expected]\n",
        "\n",
        "            return cleaned\n",
        "        except Exception as e:\n",
        "            if attempt >= max_retries:\n",
        "                raise ValueError(\n",
        "                    \"Ollama JSON parse/validation failed after retries. \"\n",
        "                    f\"Last error: {e}\\nLast raw output:\\n{last_raw}\"\n",
        "                )\n",
        "\n",
        "            prompt = (\n",
        "                \"The previous output was invalid JSON or did not match the schema.\\n\"\n",
        "                \"Return ONLY a valid JSON array matching the schema exactly.\\n\"\n",
        "                \"Do not add any commentary.\\n\\n\"\n",
        "                \"INPUT JSON:\\n\"\n",
        "                + input_json\n",
        "                + \"\\n\\nINVALID OUTPUT (for reference):\\n\"\n",
        "                + (raw if isinstance(raw, str) else str(raw))\n",
        "                + \"\\n\\nOUTPUT JSON ONLY:\"\n",
        "            )\n",
        "            time.sleep(sleep_s)\n",
        "\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e5432ce4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Turn-level rows to annotate: 14495\n",
            "TEXT_COL: text\n",
            "       split transcript_id  turn_id        row_id  \\\n",
            "0  workforce     work_0000        1  work_0000::1   \n",
            "1  workforce     work_0001        1  work_0001::1   \n",
            "2  workforce     work_0002        1  work_0002::1   \n",
            "\n",
            "                                                text  \n",
            "0  No, I don't have any questions. Let's do it! A...  \n",
            "1  That sounds good. AI: Great! Let's dive in the...  \n",
            "2  No questions, we can begin AI: Great! Let's di...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Source unique\n",
        "assert \"df_final\" in globals(), \"df_final is not defined in the notebook\"\n",
        "\n",
        "# Detect wide (human_turn_XX) vs already turn-level\n",
        "wide_turn_cols = [c for c in df_final.columns if isinstance(c, str) and c.startswith(\"human_turn_\")]\n",
        "\n",
        "if wide_turn_cols:\n",
        "    # Build turn-level table from df_final (in-memory only)\n",
        "    id_vars = [c for c in [\"split\", \"transcript_id\"] if c in df_final.columns]\n",
        "    if \"transcript_id\" not in df_final.columns:\n",
        "        raise ValueError(\"df_final must contain transcript_id\")\n",
        "    if \"split\" not in df_final.columns:\n",
        "        print(\"Warning: df_final has no 'split' column; graphs by split will be limited.\")\n",
        "\n",
        "    df_turns = df_final[id_vars + wide_turn_cols].melt(\n",
        "        id_vars=id_vars,\n",
        "        value_vars=wide_turn_cols,\n",
        "        var_name=\"turn_col\",\n",
        "        value_name=\"text\",\n",
        "    )\n",
        "    # turn_id from suffix\n",
        "    df_turns[\"turn_id\"] = df_turns[\"turn_col\"].str.replace(\"human_turn_\", \"\", regex=False)\n",
        "    df_turns[\"turn_id\"] = pd.to_numeric(df_turns[\"turn_id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    TEXT_COL = \"text\"\n",
        "else:\n",
        "    # Turn-level already\n",
        "    candidates = [\"human_text\", \"text\", \"turn_text\", \"cleaned_text\", \"utterance\"]\n",
        "    found = [c for c in candidates if c in df_final.columns]\n",
        "    if not found:\n",
        "        raise ValueError(\n",
        "            \"Could not find a text column in df_final. Expected one of \" + \", \".join(candidates)\n",
        "        )\n",
        "    TEXT_COL = found[0]\n",
        "    df_turns = df_final.copy()\n",
        "\n",
        "# Clean + drop empty\n",
        "_df_text = df_turns[TEXT_COL].apply(clean_text_basic)\n",
        "df_turns[TEXT_COL] = _df_text\n",
        "\n",
        "df_turns = df_turns[df_turns[TEXT_COL].astype(str).str.len() > 0].copy()\n",
        "\n",
        "# Stable row_id\n",
        "if \"transcript_id\" in df_turns.columns and \"turn_id\" in df_turns.columns:\n",
        "    df_turns[\"row_id\"] = df_turns[\"transcript_id\"].astype(str) + \"::\" + df_turns[\"turn_id\"].astype(str)\n",
        "else:\n",
        "    df_turns[\"row_id\"] = df_turns.index.astype(str)\n",
        "\n",
        "print(\"Turn-level rows to annotate:\", len(df_turns))\n",
        "print(\"TEXT_COL:\", TEXT_COL)\n",
        "print(df_turns[[c for c in [\"split\", \"transcript_id\", \"turn_id\", \"row_id\", TEXT_COL] if c in df_turns.columns]].head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "865ed734",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records: 14495 | batch_size: 5 | batches: 2899\n",
            "Progress: 50/14495 | annotated: 50 | failed_batches: 0\n",
            "Progress: 100/14495 | annotated: 100 | failed_batches: 0\n",
            "Progress: 150/14495 | annotated: 150 | failed_batches: 0\n",
            "Progress: 200/14495 | annotated: 200 | failed_batches: 0\n"
          ]
        }
      ],
      "source": [
        "from math import ceil\n",
        "\n",
        "batch_size = 5  # configurable\n",
        "\n",
        "MAX_CHARS = 800  # truncate input text to max 600–800 characters\n",
        "records = [\n",
        "    {\"row_id\": rid, \"text\": (txt[:MAX_CHARS] if isinstance(txt, str) else str(txt)[:MAX_CHARS])}\n",
        "    for rid, txt in zip(df_turns[\"row_id\"].astype(str), df_turns[TEXT_COL].astype(str))\n",
        "]\n",
        "\n",
        "print(\"Total records:\", len(records), \"| batch_size:\", batch_size, \"| batches:\", ceil(len(records)/batch_size))\n",
        "\n",
        "results_by_row_id = {}\n",
        "failed_batches = 0\n",
        "\n",
        "for start in range(0, len(records), batch_size):\n",
        "    batch = records[start : start + batch_size]\n",
        "    batch_ids = [b[\"row_id\"] for b in batch]\n",
        "\n",
        "    try:\n",
        "        out = call_ollama(batch)\n",
        "        for item in out:\n",
        "            results_by_row_id[item[\"row_id\"]] = item\n",
        "    except Exception as e:\n",
        "        failed_batches += 1\n",
        "        print(f\"Batch {start//batch_size + 1} failed:\", e)\n",
        "        # Continue; we'll mark missing as NA\n",
        "\n",
        "    if (start // batch_size + 1) % 10 == 0:\n",
        "        print(f\"Progress: {start + len(batch)}/{len(records)} | annotated: {len(results_by_row_id)} | failed_batches: {failed_batches}\")\n",
        "\n",
        "# Attach to df_turns\n",
        "ann = pd.DataFrame.from_records(list(results_by_row_id.values()))\n",
        "\n",
        "if ann.empty:\n",
        "    print(\"No annotations returned.\")\n",
        "    df_final_annot = df_turns.copy()\n",
        "    df_final_annot[\"label\"] = pd.NA\n",
        "    df_final_annot[\"confidence\"] = pd.NA\n",
        "    df_final_annot[\"evidence\"] = pd.NA\n",
        "else:\n",
        "    df_final_annot = df_turns.merge(ann[[\"row_id\", \"label\", \"confidence\", \"evidence\"]], on=\"row_id\", how=\"left\")\n",
        "\n",
        "print(\"Annotated turn-level df shape:\", df_final_annot.shape)\n",
        "print(df_final_annot[[c for c in [\"split\", \"transcript_id\", \"turn_id\", \"row_id\", \"label\", \"confidence\"] if c in df_final_annot.columns]].head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11024d74",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metrics Axe 1 (discours vs réalité) à partir de df_final_annot\n",
        "\n",
        "required_cols = [c for c in [\"transcript_id\", \"split\", \"label\"] if c in df_final_annot.columns]\n",
        "if \"transcript_id\" not in df_final_annot.columns or \"label\" not in df_final_annot.columns:\n",
        "    raise ValueError(\"df_final_annot must have at least transcript_id and label\")\n",
        "\n",
        "# Ordering key\n",
        "if \"turn_id\" in df_final_annot.columns:\n",
        "    order_col = \"turn_id\"\n",
        "else:\n",
        "    order_col = None\n",
        "\n",
        "rows = []\n",
        "for transcript_id, g in df_final_annot.groupby(\"transcript_id\", sort=False):\n",
        "    split = g[\"split\"].iloc[0] if \"split\" in g.columns else \"(unknown)\"\n",
        "\n",
        "    labels = g[\"label\"].dropna().astype(str)\n",
        "    has_min = (labels == \"MINIMIZATION\").any()\n",
        "    has_use = (labels == \"PRACTICAL_USE\").any()\n",
        "    discursive_gap = bool(has_min and has_use)\n",
        "\n",
        "    first_min = np.nan\n",
        "    first_use = np.nan\n",
        "\n",
        "    if order_col is not None:\n",
        "        gg = g.copy()\n",
        "        # ensure numeric order where possible\n",
        "        gg[order_col] = pd.to_numeric(gg[order_col], errors=\"coerce\")\n",
        "        gg = gg.sort_values(order_col)\n",
        "        min_rows = gg[gg[\"label\"] == \"MINIMIZATION\"]\n",
        "        use_rows = gg[gg[\"label\"] == \"PRACTICAL_USE\"]\n",
        "        if len(min_rows):\n",
        "            first_min = float(min_rows[order_col].iloc[0])\n",
        "        if len(use_rows):\n",
        "            first_use = float(use_rows[order_col].iloc[0])\n",
        "    else:\n",
        "        # fall back to appearance order in the dataframe\n",
        "        min_idx = g.index[g[\"label\"] == \"MINIMIZATION\"]\n",
        "        use_idx = g.index[g[\"label\"] == \"PRACTICAL_USE\"]\n",
        "        if len(min_idx):\n",
        "            first_min = float(min_idx.min())\n",
        "        if len(use_idx):\n",
        "            first_use = float(use_idx.min())\n",
        "\n",
        "    gap_distance = np.nan\n",
        "    if np.isfinite(first_min) and np.isfinite(first_use):\n",
        "        gap_distance = first_use - first_min\n",
        "\n",
        "    rows.append(\n",
        "        {\n",
        "            \"split\": split,\n",
        "            \"transcript_id\": transcript_id,\n",
        "            \"has_min\": has_min,\n",
        "            \"has_use\": has_use,\n",
        "            \"discursive_gap\": discursive_gap,\n",
        "            \"first_min_turn_id\": first_min,\n",
        "            \"first_use_turn_id\": first_use,\n",
        "            \"gap_distance\": gap_distance,\n",
        "        }\n",
        "    )\n",
        "\n",
        "df_metrics = pd.DataFrame(rows)\n",
        "print(\"df_metrics shape:\", df_metrics.shape)\n",
        "print(df_metrics.head())\n",
        "\n",
        "if \"split\" in df_metrics.columns:\n",
        "    print(\"\\nDiscursive gap rate by split:\")\n",
        "    print(df_metrics.groupby(\"split\")[\"discursive_gap\"].mean().sort_values(ascending=False).round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e375dbc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Bar: discursive_gap rate by split\n",
        "if \"split\" in df_metrics.columns and df_metrics[\"split\"].nunique() > 0:\n",
        "    rates = df_metrics.groupby(\"split\")[\"discursive_gap\"].mean().sort_index()\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.bar(rates.index.astype(str), rates.values)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Discursive gap rate\")\n",
        "    plt.title(\"Discursive gap rate by split\")\n",
        "    plt.xticks(rotation=20, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No 'split' available in df_metrics for split-level bar chart.\")\n",
        "\n",
        "# 2) Stacked bar: label distribution by split\n",
        "if \"split\" in df_final_annot.columns:\n",
        "    tmp = df_final_annot.copy()\n",
        "    tmp = tmp[tmp[\"label\"].notna()].copy()\n",
        "    counts = (\n",
        "        tmp.groupby([\"split\", \"label\"]).size().unstack(\"label\").fillna(0).astype(int)\n",
        "    )\n",
        "    # Ensure consistent label order\n",
        "    for col in [\"MINIMIZATION\", \"PRACTICAL_USE\", \"NEUTRAL\"]:\n",
        "        if col not in counts.columns:\n",
        "            counts[col] = 0\n",
        "    counts = counts[[\"MINIMIZATION\", \"PRACTICAL_USE\", \"NEUTRAL\"]]\n",
        "\n",
        "    splits = counts.index.astype(str)\n",
        "    bottoms = np.zeros(len(counts))\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    for lab in counts.columns:\n",
        "        vals = counts[lab].values\n",
        "        plt.bar(splits, vals, bottom=bottoms, label=lab)\n",
        "        bottoms += vals\n",
        "\n",
        "    plt.ylabel(\"# turns\")\n",
        "    plt.title(\"Label distribution by split (turn-level)\")\n",
        "    plt.xticks(rotation=20, ha=\"right\")\n",
        "    plt.legend(title=\"label\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No 'split' available in df_final_annot for stacked bar chart.\")\n",
        "\n",
        "# 3) Histogram: gap_distance overall\n",
        "vals = df_metrics[\"gap_distance\"].dropna().astype(float)\n",
        "if len(vals):\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.hist(vals.values, bins=30)\n",
        "    plt.xlabel(\"gap_distance (first_use - first_min)\")\n",
        "    plt.ylabel(\"# transcripts\")\n",
        "    plt.title(\"Distribution of gap_distance\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No finite gap_distance values to plot.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40df0487",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "out_dir = Path(\"./out\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Exports finaux\n",
        "(df_final_annot).to_csv(out_dir / \"df_final_annot.csv\", index=False)\n",
        "(df_metrics).to_csv(out_dir / \"df_metrics.csv\", index=False)\n",
        "\n",
        "# Parquet (si dépendance dispo)\n",
        "try:\n",
        "    (df_final_annot).to_parquet(out_dir / \"df_final_annot.parquet\", index=False)\n",
        "    print(\"Saved Parquet:\", out_dir / \"df_final_annot.parquet\")\n",
        "except Exception as e:\n",
        "    print(\"Parquet export skipped (missing engine like pyarrow/fastparquet). Error:\", e)\n",
        "\n",
        "print(\"Saved:\", out_dir / \"df_final_annot.csv\", \"and\", out_dir / \"df_metrics.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d58237a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Model switch (Ollama) ---\n",
        "# Switch the local model used for annotation.\n",
        "\n",
        "MODEL = \"mistral-7b-instruct\"  # or: \"llama3.1:13b-instruct\"\n",
        "MODEL_NAME = MODEL  # backward-compat for earlier cells\n",
        "\n",
        "# Verify Ollama is reachable + model is available\n",
        "r = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\", timeout=10)\n",
        "r.raise_for_status()\n",
        "tags = r.json()\n",
        "model_names = [m.get(\"name\") for m in tags.get(\"models\", []) if isinstance(m, dict)]\n",
        "print(\"Ollama OK. Models available (sample):\", model_names[:10])\n",
        "\n",
        "if MODEL not in model_names:\n",
        "    print(f\"\\nModel '{MODEL}' not found in /api/tags.\")\n",
        "    print(f\"Run: ollama pull {MODEL}\")\n",
        "else:\n",
        "    print(f\"Model found: {MODEL}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a626ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- call_ollama override to use MODEL ---\n",
        "# Same logic as before, only switching the target model + num_predict.\n",
        "\n",
        "\n",
        "def call_ollama(batch_records, max_retries=2, sleep_s=0.5):\n",
        "    \"\"\"Call Ollama generate API with strict JSON parsing + repair retries.\"\"\"\n",
        "    if not isinstance(batch_records, list) or not batch_records:\n",
        "        return []\n",
        "\n",
        "    input_json = json.dumps(batch_records, ensure_ascii=False)\n",
        "\n",
        "    base_prompt = (\n",
        "        \"INPUT JSON:\\n\"\n",
        "        + input_json\n",
        "        + \"\\n\\nOUTPUT JSON ONLY:\"  # force strict\n",
        "    )\n",
        "\n",
        "    def _post(prompt_text):\n",
        "        payload = {\n",
        "            \"model\": MODEL,\n",
        "            \"stream\": False,\n",
        "            \"system\": SYSTEM_PROMPT,\n",
        "            \"prompt\": prompt_text,\n",
        "            \"options\": {\n",
        "                \"temperature\": 0,\n",
        "                \"num_predict\": 120,\n",
        "            },\n",
        "        }\n",
        "        r = requests.post(\n",
        "            f\"{OLLAMA_BASE_URL}/api/generate\",\n",
        "            json=payload,\n",
        "            timeout=(10, None),\n",
        "        )\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        return data.get(\"response\", \"\")\n",
        "\n",
        "    prompt = base_prompt\n",
        "    last_raw = None\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        raw = _post(prompt)\n",
        "        last_raw = raw\n",
        "        try:\n",
        "            parsed = strict_json_load(raw)\n",
        "            if not isinstance(parsed, list):\n",
        "                raise ValueError(\"Top-level JSON must be an array\")\n",
        "\n",
        "            cleaned = [_validate_annotation_item(x) for x in parsed]\n",
        "\n",
        "            expected = {str(r.get(\"row_id\")) for r in batch_records}\n",
        "            cleaned = [x for x in cleaned if x[\"row_id\"] in expected]\n",
        "\n",
        "            return cleaned\n",
        "        except Exception as e:\n",
        "            if attempt >= max_retries:\n",
        "                raise ValueError(\n",
        "                    \"Ollama JSON parse/validation failed after retries. \"\n",
        "                    f\"Last error: {e}\\nLast raw output:\\n{last_raw}\"\n",
        "                )\n",
        "\n",
        "            prompt = (\n",
        "                \"The previous output was invalid JSON or did not match the schema.\\n\"\n",
        "                \"Return ONLY a valid JSON array matching the schema exactly.\\n\"\n",
        "                \"Do not add any commentary.\\n\\n\"\n",
        "                \"INPUT JSON:\\n\"\n",
        "                + input_json\n",
        "                + \"\\n\\nINVALID OUTPUT (for reference):\\n\"\n",
        "                + (raw if isinstance(raw, str) else str(raw))\n",
        "                + \"\\n\\nOUTPUT JSON ONLY:\"\n",
        "            )\n",
        "            time.sleep(sleep_s)\n",
        "\n",
        "    return []\n",
        "\n",
        "\n",
        "print(\"call_ollama now using MODEL =\", MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a914efa",
      "metadata": {},
      "source": [
        "### 2ème analyse : l'IA transforme le travail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "421a3585",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "3.9.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
